{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6491300f",
   "metadata": {},
   "source": [
    "# Perceptron Model & MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc71f6b",
   "metadata": {},
   "source": [
    "- [x] Dataset generation\n",
    "- [x] Perceptron\n",
    "    - [x] Activiation functions\n",
    "    - [x] init\n",
    "    - [x] fit\n",
    "    - [x] predict\n",
    "- [x] Neural Network\n",
    "    - [x] init\n",
    "    - [x] fit\n",
    "    - [x] predict\n",
    "- [x] Global script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a8335",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Here we import the different libraries and modules to run the code.\n",
    "And we add an autoreload feature to retrieve the last version of the python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d579451",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85de1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import uniform\n",
    "\n",
    "from perceptron import Perceptron \n",
    "from neuralnetwork import NeuralNetwork "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc6d5b",
   "metadata": {},
   "source": [
    "### Dataset Generation\n",
    "\n",
    "Not sure about the most appropriate form of the data. Therefore there is 2 different output functions:\n",
    "- generate_data_df: create the data as a Dataframe\n",
    "- generate_data_array: split the data into a outputs 2D array and a target 1D array\n",
    "\n",
    "Even if in the code, the target was set either -1 or 1, I decided to put it between 0 and 1.\n",
    "\n",
    "Not sure also about the value of features :\n",
    "- float from -1 to 1\n",
    "- boolean -1 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3afb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_df(size, features):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        size: (int) number of samples -> m\n",
    "        features : (int) number of features -> n\n",
    "    Return:\n",
    "        (Dataframe) with m samples labeled, n features [x0, xn] and the output y \n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        # dataset\n",
    "        [[uniform(-1.0, 1.0) for _ in range(features + 1)] for _ in range(size)],\n",
    "        # labels\n",
    "        columns=[str(f\"x{i}\") for i in range(features)] + ['y'])\n",
    "    \n",
    "def generate_dataset_array(size, features):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        size: (int) number of samples -> m\n",
    "        features : (int) number of features -> n\n",
    "    Return:\n",
    "        \n",
    "    \"\"\"\n",
    "    # value between -1. and 1\n",
    "    features = np.asarray([np.asarray([uniform(-1., 1.) for _ in range(features)]) for _ in range(size)])\n",
    "    # value between 0. and 1.\n",
    "#     features = np.asarray([np.asarray([uniform(0., 1.) for _ in range(features)]) for _ in range(size)])\n",
    "    # value 0 or 1\n",
    "#     features = np.asarray([np.random.randint(2, size=features) for _ in range(size)])\n",
    "\n",
    "    # value between -1. and 1.\n",
    "#     targets = np.heaviside(np.asarray([uniform(-1., 1.) for _ in range(size)]), 0)\n",
    "    # value 0 or 1\n",
    "    targets = np.random.randint(2, size=size)\n",
    "    \n",
    "    features[features==0] = -1.\n",
    "#     targets[targets==0] = -1\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346d8c",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "Here we are creating a perceptron to check if the gradient descent is working.\n",
    "Apparently it is working for the 4 activiation function because of the error decreasing.\n",
    "Need some adjustement on the learing rate to not overshoot sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e641a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELU       Initial target: 0 | Model ouput: 0.0\n",
      "SIGMOID    Initial target: 0 | Model ouput: 0.03988277582795911\n",
      "HEAVISIDE  Initial target: 0 | Model ouput: 0.0\n",
      "TANH       Initial target: 0 | Model ouput: -1.9102625037348275e-10\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "x, y = generate_dataset_array(1, 10)\n",
    "# Testing on the first element\n",
    "test_x, test_y = x[0], y[0]\n",
    "\n",
    "activation_functions = ['relu', 'sigmoid', 'heaviside', 'tanh']\n",
    "for activation_function in activation_functions:\n",
    "    perceptron = Perceptron(10, activation_function)\n",
    "    for _ in range(20):\n",
    "        perceptron.fit(test_x, test_y, 0.3)\n",
    "    print(f\"{activation_function.upper().ljust(10)} Initial target: {test_y} | Model ouput: {perceptron.predict(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4c364",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "Here is the main part, with the context of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbcf071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop: 0%\n",
      "Training loop: 10%\n",
      "Training loop: 20%\n",
      "Training loop: 30%\n",
      "Training loop: 40%\n",
      "Training loop: 50%\n",
      "Training loop: 60%\n",
      "Training loop: 70%\n",
      "Training loop: 80%\n",
      "Training loop: 90%\n",
      "Prediction: [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# TRAINING_LOOP = 500_000\n",
    "TRAINING_LOOP = 10000\n",
    "DATASET_SIZE = 8\n",
    "DATASET_FEATURES = 6\n",
    "LEARNING_RATE = 1.2\n",
    "\n",
    "neural_network = NeuralNetwork(6, [100], 3)\n",
    "# neural_network = NeuralNetwork(6, [10], 1)\n",
    "X, y = generate_dataset_array(DATASET_SIZE, DATASET_FEATURES)\n",
    "\n",
    "for i in range(TRAINING_LOOP):\n",
    "    if (i%1000 == 0):\n",
    "        print(f\"Training loop: {i*100//TRAINING_LOOP}%\")\n",
    "    for inputs, target in zip(X, y):\n",
    "        neural_network.fit(inputs, target, LEARNING_RATE)\n",
    "\n",
    "predictions = neural_network.predict(np.array([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]))\n",
    "print(f\"Prediction: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3928e",
   "metadata": {},
   "source": [
    "### New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe38ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    iris = datasets.load_iris()\n",
    "    data_X = np.asarray(iris['data'])\n",
    "    data_Y = np.asarray(iris['target'])\n",
    "    data_Y = data_Y.reshape(np.shape(data_Y)[0], 1)\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    data_Y = enc.fit_transform(data_Y).toarray()\n",
    "    \n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a78d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_LOOP = 10000\n",
    "DATASET_SIZE = 8\n",
    "DATASET_FEATURES = 6\n",
    "LEARNING_RATE = 1.2\n",
    "\n",
    "neural_network = NeuralNetwork(6, [100], 3)\n",
    "# neural_network = NeuralNetwork(6, [10], 1)\n",
    "X, y = generate_dataset_array(DATASET_SIZE, DATASET_FEATURES)\n",
    "\n",
    "for i in range(TRAINING_LOOP):\n",
    "    if (i%1000 == 0):\n",
    "        print(f\"Training loop: {i*100//TRAINING_LOOP}%\")\n",
    "    for inputs, target in zip(X, y):\n",
    "        neural_network.fit(inputs, target, LEARNING_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
